---
layout: post
title: Elasticsearch Bulk API Example and Performance Comparison
date: 2017-04-14 10:14:10.000000000 +05:30
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories:
- Elasticsearch
tags:
- bulk-api
- performance
meta:
  _edit_last: '44162397'
  _pt_cv_view_count: '175'
  _aioseop_title: Elasticsearch Bulk API Example
  dpsp_networks_shares: a:2:{s:11:"google-plus";i:0;s:9:"pinterest";i:0;}
  original_post_id: '170'
  _wp_old_slug: '170'
  _publicize_job_id: '6472189977'
author:
  login: sureshsarda
  email: sureshssarda@gmail.com
  display_name: Suresh Sarda
  first_name: ''
  last_name: ''
---
<p>Elasticsearch provide bulk operations to perform multiple operations in a single call. Bulk APIs can be accessed by hitting the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html">/_bulk</a> endpoint.<br />
This post demonstrates the use of bulk API with Python. It assumes that you are familiar (not expert) with <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html">REST Bulk API of Elasticsearch</a>. To keep it simple we will just consider the insertion case.</p>
<h2 id="problem-statement">Problem Statement</h2>
<p>Before we jump into code, let’s take a minute and think about the problem in hand. We have some data that we need to insert into Elasticsearch. So to break the problem: we have data generation module that provides us data. At times, we cannot directly insert the data in the database. We need to perform some sort of processing on the data before inserting it. After this, we can send these documents to Elasticsearch. So, we have 3 steps (or phases):<br />
1. Data generation<br />
2. Processing of data<br />
3. Insertion</p>
<h2 id="elasticsearch-py"><a href="http://elasticsearch-py.readthedocs.io/en/master/index.html">elasticsearch-py</a></h2>
<p>We are going to use elasticsearch-py. Bulk APIs are provided as <a href="http://elasticsearch-py.readthedocs.io/en/master/helpers.html">helper method in elasticsearch-py</a>. Let’s now write code for each step.</p>
<h3 id="data-generation">Data Generation</h3>
<p>Data can be generated anyhow. It could be read from a file or from any other database or from a socket. It doesn’t matter. For this example, I’ll generate some random data.</p>
<p>[code language="python"]<br />
def generate_doc(count=10):<br />
    &quot;&quot;&quot;<br />
    Creates a document with random username, random salary amount, random profession and a date of birth<br />
    :param count: number of documents to return<br />
    :return: generator object for user documents<br />
    &quot;&quot;&quot;<br />
    def generate_username():<br />
        return ''.join(random.choice(string.ascii_lowercase) for _ in range(10))<br />
    def generate_profession():<br />
        return random.choice(['Accountant', 'Doctor', 'Engineer', 'Realtor', 'Writer'])<br />
    def generate_user_doc():<br />
        return dict(<br />
            username=generate_username(),<br />
            profession=generate_profession(),<br />
            salary=random.randint(1000, 100000)<br />
        )<br />
    random.seed(33)<br />
    for i in range(count):<br />
        yield generate_user_doc()<br />
[/code]</p>
<h3 id="data-generation">Data Processing</h3>
<p>Okay, so we have our data. Now we need to process this. This step is required if you are copying the data from some other database to ES and need to perform some processing. But since we have the data in the correct format, we will just skip this step.</p>
<p>[code language="python"]<br />
def process_document(document):<br />
    # Add document processing here<br />
    return document<br />
[/code]</p>
<p>You could add your implementation in this method.</p>
<h3 id="data-generation">Bulk Insertion</h3>
<p>Alright, now we have all the data we need. Let’s store it. But before we store there’s something that we need to consider. The body of bulk API should contain the some metadata. It should contain the <em>operation</em> we need to perform, what <em>index</em> and what <em>type</em> to perform on, etc. For every document we need this metadata. Let’s write one more method that adds this information.</p>
<p>[code language="python"]<br />
def create_bulk_api_query(document_generator, index, type, action='index'):</p>
<p>    for doc in document_generator:<br />
        d = dict(<br />
            _op_type=action,<br />
            _index=index,<br />
            _type=type,<br />
            _source=doc<br />
        )<br />
        yield d<br />
[/code]</p>
<p>This function takes the generator object we created earlier and returns it’s own generator object that adds some metadata to the document. Simple.<br />
Next we perform the operation. And this is as simple as executing this one statement:</p>
<p>[code language="python"]<br />
success, failed = bulk(client, create_bulk_api_query(documents, index=index, type=type))<br />
[/code]</p>
<p>We have passed an Elasticsearch client, the generator object and the index and type to perform the operations on. It returns a tuple with 2 fields – success count and failure count. That's it!<br />
The complete script can be found <a href="https://github.com/sureshsarda/scripts/blob/master/bulk_api.py">here</a>.</p>
<h2>Comparing Performance with regular inserts:</h2>
<p>So I tried to insert some documents with bulk API. It looked fast to me. It had to be. But the results I found were astonishing:</p>
<table border="0" cellspacing="0">
<colgroup span="4" width="85"></colgroup>
<tbody>
<tr>
<td align="left" height="17">Documents</td>
<td align="left">One By One</td>
<td align="left">Bulk</td>
<td align="left">Gain</td>
</tr>
<tr>
<td align="right" height="17">100</td>
<td align="right">1.3989231586</td>
<td align="right">0.1614105701</td>
<td align="right">8.6668621354</td>
</tr>
<tr>
<td align="right" height="17">1000</td>
<td align="right">10.0419487953</td>
<td align="right">0.3521802425</td>
<td align="right">28.5136631258</td>
</tr>
<tr>
<td align="right" height="17">10000</td>
<td align="right">64.6501646042</td>
<td align="right">2.8116579056</td>
<td align="right">22.9936097403</td>
</tr>
<tr>
<td align="right" height="17">100000</td>
<td align="right">600.7230203152</td>
<td align="right">17.1942903996</td>
<td align="right">34.9373545727</td>
</tr>
</tbody>
</table>
<p>Plotting it:</p>
<p><img class=" size-full wp-image-178 aligncenter" src="{{ site.baseurl }}/assets/png-image-605c2a0c397c2a0340-pixels.png" alt="(PNG Image, 605 × 340 pixels)" width="605" height="340" /></p>
<p>I was expecting a 5x or 10x gain. 34X at 100k documents is a lot!</p>
<p>Note: This is not a benchmarking study. These are just approximate results and should be used only as guideline.</p>
