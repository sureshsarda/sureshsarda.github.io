<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>how to on s9a.me</title><link>s9a.me/category/how-to/</link><description>Recent content in how to on s9a.me</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 10 Dec 2019 00:00:00 +0000</lastBuildDate><atom:link href="s9a.me/category/how-to/index.xml" rel="self" type="application/rss+xml"/><item><title>Convert String to title case in Java using Streams</title><link>s9a.me/java/convert-string-title-case-java-streams/</link><pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate><guid>s9a.me/java/convert-string-title-case-java-streams/</guid><description>Title case is capitalized first character of each word. That means, we have to do this:
Break at word boundaries Capitalize the first character and lowercase the others Join again at word boundaries. public String toTitleCase(String str) { final String wordBoundary = &amp;#34; &amp;#34;; return Arrays.stream(str.split(wordBoundary)) .map(it -&amp;gt; it.substring(0, 1).toUpperCase() + it.substring(1, it.length()).toLowerCase()) .collect(Collectors.joining(wordBoundary)); } Let&amp;rsquo;s see it in actions:
Roughing It =&amp;gt; Roughing It PRIde AnD PrejudICE =&amp;gt; Pride And Prejudice a tale of two Cities =&amp;gt; A Tale Of Two Cities</description></item><item><title>Insert, Index document in Elasticsearch using Java</title><link>s9a.me/elasticsearch/insert-index-document-elasticsearch-java/</link><pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate><guid>s9a.me/elasticsearch/insert-index-document-elasticsearch-java/</guid><description>In this article we will see how to insert a document in Elasticsearch using the High Level Client provided by Elasticsearch.
Prepare the Index Request Elasticsearch client accepts IndexRequest to insert documents. Two required details for this request are:
Name of the index Document source Everything else can take default value. We will stick to the easy path to create our very first document and explore other optional arguments later.</description></item><item><title>Search Elasticsearch from Java using High Level Client</title><link>s9a.me/elasticsearch/search-match-all-from-java-using-high-level-client/</link><pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate><guid>s9a.me/elasticsearch/search-match-all-from-java-using-high-level-client/</guid><description>In [the last post]({% post_url elasticsearch/2019-11-25-connecting-to-elasticsearch-from-java %}) we saw how to connect to Elasticsearch using the High Level Client.
match_all Query using Java client The client provides many high level methods to build an Elasticsearch query. To keep it simple, let&amp;rsquo;s see how to construct a simple match_all query:
SearchRequest request = new SearchRequest(&amp;#34;online&amp;#34;); // -- 1 SearchSourceBuilder builder = new SearchSourceBuilder(); // -- 2 builder.query(QueryBuilders.matchAllQuery()); request.source(builder); // -- 3 Parameter to the constructor is the index you want to query, this can be left empty and all the indices will be queried SearchSourceBuilder is used to create a search request.</description></item><item><title>Connect to Elasticsearch using Java High Level Client</title><link>s9a.me/elasticsearch/connect-from-java-using-high-level-client/</link><pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate><guid>s9a.me/elasticsearch/connect-from-java-using-high-level-client/</guid><description>Elasticsearch provides a client to conveniently connect with Elasticsearch. Create a Maven project and add the following maven dependency:
Add Maven Dependency &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.elasticsearch.client&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;elasticsearch-rest-high-level-client&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;7.3.1&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; Set Up connection with Elasticsearch Elasticsearch maintains 2 clients - Low Level Client and High Level Client. It is recommended to use the High Level Client to query and index documents in Elasticsearch. You can create connection to Elasticsearch like this:
RestHighLevelClient client = new RestHighLevelClient( RestClient.</description></item><item><title>Spring REST - Extract URL Path Variables</title><link>s9a.me/java/spring/extract-use-parse-url-path-data-variable/</link><pubDate>Sun, 24 Nov 2019 00:00:00 +0000</pubDate><guid>s9a.me/java/spring/extract-use-parse-url-path-data-variable/</guid><description>REST APIs have resource names and resource id present in the URL path unlike a traditional web API. This article focuses on how to extract that information and use it.
Take a typical REST URL:
GET https://api.bookstore.com/authors/twain-mark/books/roughing-it Here, the name of the author and the name of the book are inside the book and not part of the request body or query parameters. This is a standard practice while developing REST APIs.</description></item><item><title>Spring - Read Http Request headers</title><link>s9a.me/java/spring/request-headers-in-spring-rest/</link><pubDate>Sat, 23 Nov 2019 00:00:00 +0000</pubDate><guid>s9a.me/java/spring/request-headers-in-spring-rest/</guid><description>In the previous article we saw how to use request parameters and request body of a request. In this article we will see how to use the request headers.
The request headers can be accessed using the @RequestHeader attribute.
@RequestMapping(&amp;#34;/greeting&amp;#34;) public ResponseEntity&amp;lt;String&amp;gt; greeting(@RequestHeader(&amp;#34;Accept-Language&amp;#34;) String language, @RequestHeader(&amp;#34;Content-Type&amp;#34;) String contentType) { // do something with the headers return new ResponseEntity&amp;lt;String&amp;gt;(String.format(&amp;#34;Language: %s, Content Type: %s&amp;#34;, language, contentType), HttpStatus.OK); } Note that the name of the header field is case insensitive.</description></item><item><title>Java 8 Streams 101</title><link>s9a.me/java/introduction-to-java-streams-101/</link><pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate><guid>s9a.me/java/introduction-to-java-streams-101/</guid><description>Java 8 introduced a new Stream API. In this article we will take a look at how to create and use streams.
How do I create Streams? Streams can be created using the of method on the Stream class like this:
Stream&amp;lt;String&amp;gt; stream = Stream.&amp;lt;String&amp;gt;of(&amp;#34;Lorem&amp;#34;, &amp;#34;ipsum&amp;#34;, &amp;#34;dolor&amp;#34;, &amp;#34;sit&amp;#34;, &amp;#34;amet&amp;#34;); Or calling the stream() method on list or any collection like this:
List&amp;lt;String&amp;gt; list = Arrays.asList(&amp;#34;Lorem&amp;#34;, &amp;#34;ipsum&amp;#34;, &amp;#34;dolor&amp;#34;, &amp;#34;sit&amp;#34;, &amp;#34;amet&amp;#34;); Stream&amp;lt;String&amp;gt; stream = list.</description></item><item><title>Creating CSV from Strings in Java</title><link>s9a.me/java/creating-csv-from-strings/</link><pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate><guid>s9a.me/java/creating-csv-from-strings/</guid><description>Earlier in Java 7, you needed a StringBuilder to create a CSV from list. From Java 8 onwards, there are multiple ways to achieve this depending on the task in hand.
1. Using the String.join method The String class has a join method that take a delimiter.
List&amp;lt;String&amp;gt; tokens = Arrays.asList(&amp;#34;one&amp;#34;, &amp;#34;two&amp;#34;, &amp;#34;three&amp;#34;); String joined = String.join(&amp;#34;,&amp;#34;, tokens); System.out.println(joined); // --output -- // one,two,three 2. Using the StringJoiner Another similar way to achieve this is using the StringJoiner class.</description></item><item><title>Create your first Docker container</title><link>s9a.me/posts/2019-09-28-creating-your-first-docker-image/</link><pubDate>Sat, 28 Sep 2019 10:00:00 +0000</pubDate><guid>s9a.me/posts/2019-09-28-creating-your-first-docker-image/</guid><description>Part 1 of a multi-part essay on configuring Docker in production.
Prerequisites You have Docker installed (See instructions to install) (Optional) You know to to deploy a Flask application using command line Docker works on basis of configurations. It&amp;rsquo;s a declarative way of telling Docker how to build images.
A typical workflow starts with a base image, works on top of it, saves it either for future use or gets reused as a base image of something else.</description></item><item><title>Pandas: Splitting (Exploding) a column into multiple rows</title><link>s9a.me/posts/2018-11-21-pandas-splitting-exploding-string-column-into-multiple-rows/</link><pubDate>Wed, 21 Nov 2018 10:00:00 +0000</pubDate><guid>s9a.me/posts/2018-11-21-pandas-splitting-exploding-string-column-into-multiple-rows/</guid><description>Recently, while working with on something in my office, I faced a small but interesting problem. I had to clean some data and the data was not normalized. In one of the columns, a single cell had multiple comma seperated values. I could not find out the distribution of how frequently the value was appearing without splitting these cells into individual cells of their own; creating new rows.
Example:
# Input data: EmployeeId, City 001, Mumbai|Bangalore 002, Pune|Mumbai|Delhi 003, Mumbai|Bangalore 004, Mumbai|Pune 005, Bangalore .</description></item><item><title>Running in Pig in Local Mode in Java</title><link>s9a.me/posts/2018-08-01-running-hadoop/</link><pubDate>Wed, 01 Aug 2018 07:11:02 +0000</pubDate><guid>s9a.me/posts/2018-08-01-running-hadoop/</guid><description>Overview of steps Create a new maven project Add Hadoop and Pig dependencies Write a small pig script to count words in a file Write a driver program that will run this pig script 1. Create a new maven project mvn archetype:generate -DgroupId=com.example -DartifactId=piglocal -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false You can now import the project in your IDE.
2. Add Hadoop and Pig dependencies Pig needs the following dependencies:
&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.pig&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;pig&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;0.17.0&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;log4j&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;log4j&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.</description></item><item><title>Running Spark Locally</title><link>s9a.me/posts/2018-01-30-running-spark-locally/</link><pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate><guid>s9a.me/posts/2018-01-30-running-spark-locally/</guid><description>Running distributed applications on local machine might seem like a tedious task, but apparently it’s pretty easy.
1. Download and extract the binary The binary can be downloaded from here, extract it somewhere, let’s call it SPARK_HOME
2. Running the master cd $SPARK_HOME/sbin ./start-master.sh Verify permissions if you are not able to run it
The script will emit some log statement and a URL where master is running. On local machine this will be of format: spark://your-machine-name:7077</description></item><item><title>Boilerplate - Logging in Python</title><link>s9a.me/posts/2017-08-03-boilerplate-for-logging-in-python/</link><pubDate>Thu, 03 Aug 2017 00:00:00 +0000</pubDate><guid>s9a.me/posts/2017-08-03-boilerplate-for-logging-in-python/</guid><description>This is how all my Python scripts look like when they start:
import logging logging.basicConfig(level=logging.DEBUG) logger = logging.getLogger(__name__) logger.debug(&amp;#39;Log message&amp;#39;) Nothing much but I prefer logging over print statements. Whenever I want to move this small script to larger project, I don&amp;rsquo;t have to make lot of changes. Logging also offers more control over the messages and what messages to print or skip.</description></item><item><title>Elasticsearch Bulk API Example and Performance Comparison</title><link>s9a.me/posts/elasticsearch/2017-04-14-elasticsearch-bulk-api-example-and-performance-comparison/</link><pubDate>Fri, 14 Apr 2017 10:14:10 +0000</pubDate><guid>s9a.me/posts/elasticsearch/2017-04-14-elasticsearch-bulk-api-example-and-performance-comparison/</guid><description>Elasticsearch provides bulk operations to perform multiple operations in a single call. Bulk APIs can be accessed by hitting the _bulk endpoint. This post demonstrates the use of bulk API with Python. It assumes that you are familiar (not expert) with REST Bulk API of Elasticsearch. To keep it simple we will just consider the insertion case.
Problem Statement Before we jump into code, let’s take a minute and think about the problem in hand.</description></item><item><title>Bash: Setting variables from a file</title><link>s9a.me/posts/linux/2016-10-30-bash-setting-variables-from-a-file/</link><pubDate>Sun, 30 Oct 2016 00:00:00 +0000</pubDate><guid>s9a.me/posts/linux/2016-10-30-bash-setting-variables-from-a-file/</guid><description>Shell scripts sometimes get overly complicated and we need lot of configurations stored in file instead of setting them in ten different files which not to mention is error prone. A simple technique would be to write all the configurations in a properties file and read it in all the scripts.
Create the variables file For example we have all these configurations we need to set
server.build.ip=10.20.0.17 server.stage.ip=10.20.0.77 server.stage.user=stageuser server.stage.user.sudo=stageadmin server.</description></item><item><title>Weekly Unix #2 - du</title><link>s9a.me/posts/linux/2016-06-26-weekly-unix-2-du/</link><pubDate>Sun, 26 Jun 2016 00:00:00 +0000</pubDate><guid>s9a.me/posts/linux/2016-06-26-weekly-unix-2-du/</guid><description>du = Disk Usage du summarizes the disk usage for files and folders.
How to use du This will list size of all the files as well as folders in the current directory. The folders will be explored recursively. That means all the files in the folders will be listed as well.
The above gets bit out of hand when you have lot of files. You won&amp;rsquo;t be able to figure out what is happening as lot of entries will go from your eyes.</description></item><item><title>Practical Emacs Tip #1: Meet the C-x z command</title><link>s9a.me/posts/linux/2016-06-10-practical-emacs-tip-1-meet-the-c-x-z-command/</link><pubDate>Fri, 10 Jun 2016 00:00:00 +0000</pubDate><guid>s9a.me/posts/linux/2016-06-10-practical-emacs-tip-1-meet-the-c-x-z-command/</guid><description>The Emacs manual simply states that &amp;ldquo;Repear the most recently executed command&amp;rdquo;.
This command just repeats the last command with the last given set of arguments to that command (if any). No rocket science. Just simple Emacs!
By the way, before we start there is one more thing - Once you press C-x z, you can repeatedly press only z for the command to repeat itself! No need to press C-x again and again.</description></item><item><title>Weekly Unix</title><link>s9a.me/posts/linux/2016-06-08-weekly-unix-tr/</link><pubDate>Wed, 08 Jun 2016 00:00:00 +0000</pubDate><guid>s9a.me/posts/linux/2016-06-08-weekly-unix-tr/</guid><description>tr - translate TR basically stands for translate. The man page says - translate or delete character. So tr is used to manipulate the byte stream provided to it. This command again is very powerful when combined with other commands. For example you want to rename files to lower case (thought there are other methods for this), or you want to change a (or a set of) character in a file or from a live stream, this is the utility you will need.</description></item></channel></rss>